#django_dragon_rattelyr [▣](http://www.wizards.com/dnd/images/ssouth_gallery/84369.jpg) [┌](http://www.scribd.com/doc/78401264/53/Dragon-Rattelyr) [t](http://twitter.com/RattelyrDragon) | [REQS](.requirements) [LICENSE](LICENSE)

#ID

Rattelyr dragon
Breath weapon: cone of fire
Terrain: desert, the forest, grassy plains
Alignment: lawful evil
Image: http://www.wizards.com/dnd/images/ssouth_gallery/84369.jpg
Notes: it is unusually short-lived for a dragon
Appears in: Shining South
@source http://www.thefullwiki.org/Dragon_(Dungeons_%26_Dragons)#Rattelyr_dragon

#note Something bs4 might give after stripping.

#REQS

  1. [ccv](http://libccv.org/post/introducing-ccv-milestone/) (for FacePi)
  2. [pareidoloop](http://iobound.com/pareidoloop/) (for FacePi)
  3. D&D Profile -> Twitter Web Presence/Identity 

#IDEAS

	* GesturePi (ascii-image-tile gesture-invoked snapshots from USB camera input as target for hopfield system that quickly learns to isolate arbitary entites from focal point average-frames within bounds determined by concentric circles, functioning as a finite-Cartesian ergonomic UI; essentially, pointing invokes or triggers the bounded-matrix as gestures play on canonical images developed from ascii-tiles; it's simple tile printing as a memory structure for hopfield networks; but gesture differentiation from images is important; a USB camera could start video from base pointing-gesture, then wait until gestures to interpret canonical geometric form contrasts derived from ascii-tile variations -- if a dense form is recorded by the USB camera, this outlines an initial snapshot-frame, where the density travels implies an geometric norm-pattern that serves as training data to gesture UI): For issuing commands.

			* |	-----G<---------------------- |
			* |	    / 	\					  |
			* |	   / 	 \  [O]				  |
			* |--/(G)-------G^-\------^(O)----|
			* |			     |/	\      /     \|
			* |              |\	 \----O>     /|
			* |	----------------------------- |

	* FacePi (face_evolutionary_generator :: hopfield_recurrent_ccv_trainer; ascii face-maps written in coffeejson): For a dragon that can love /you/ back.
	* FlyPi ([pi-motor](https://github.com/rakeshpai/pi-motor); #see AR Drone 2.0 since it gets "miraculous" testimonials) : For fine-flight movement (two motors). Consider ``cputhrottle`` to choke the Pi into subtlty.
	* Pyrrative (Sui generis species generation from narrative models; TBD): For the character-trait edge in evolutionary scenarios with environment activity strictures over agent-object dynamics.
		* Web scraping (http://www.thefullwiki.org/Dragon_(Dungeons_%26_Dragons)#Rattelyr_dragon, http://quiz.thefullwiki.org/Dragon_(Dungeons_&_Dragons)?print=1) with #pandoc; e.g. $ pandoc -f html -t json ${url} #with some grep)
	* Epigenetic Constraints (@see http://www.nature.com/nbt/journal/v30/n8/full/nbt.2269.html, http://www.nature.com/news/artificial-jellyfish-built-from-rat-cells-1.11046): For discussion of lowest cost materials for a biosynthetic shell/husk.
	* Species descriptive topolgy system based on ┌ through ╋  at [copypastecharacter.com](http://copypastecharacter.com/all-characters)
	* DNS Ideas: ``http://drag.one/``, ``http://humano.ide/``, ``http://en.te/, http://mindflaye.re/`` (the "e" indicates W3C PROV "Entity" status of ontology)
	* Hardwar: Dual Altoids Tin+Cedar Wood Exoskelaton Chassis mounting polymer solar cell (PSC)/graphene wing-span redundant nanopower grid system and synchronized visuodata input camera systems [1](http://physicsworld.com/cws/article/news/2012/jan/26/graphene-could-be-a-perfect-absorber-of-light)
	* Emotion Trending System based on Descriptive Markup Analysis [2](http://www.w3.org/TR/emotionml/) on GPS Tracking of localized Twitter/Foursquare Profiles
	* Consider changing project name to "django_dragon"
	* Need pseudoendocrine system layout #hardwar
	* Need audition system

#LEFTOVERS

1. pandoc -f html -t json "http://www.thefullwiki.org/Dragon_(Dungeons_%26_Dragons)#wikipedia_Pyroclastic_dragon
2. py -c "from bs4 import BeautifulSoup;" #get #id'd content from pandoc
3. ...

