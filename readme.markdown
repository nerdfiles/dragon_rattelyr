#[django_dragon_rattelyr](https://github.com/nerdfiles/dragon_rattelyr) [▣](FIGURE.jpg) [┌](http://www.scribd.com/doc/78401264/53/Dragon-Rattelyr) [t](http://twitter.com/RattelyrDragon) | [REQS](.requirements) [LICENSE](LICENSE)

#ID

Rattelyr dragon
Breath weapon: cone of fire
Terrain: desert, the forest, grassy plains
Alignment: lawful evil
Image: http://www.wizards.com/dnd/images/ssouth_gallery/84369.jpg
Notes: it is unusually short-lived for a dragon
Appears in: Shining South
@source http://www.thefullwiki.org/Dragon_(Dungeons_%26_Dragons)#Rattelyr_dragon

#note Something bs4 might give after stripping.

#TEAM

1. nerdfiles (http://nerdfiles.net, [@filesofnerds](http://twitter.com/filesofnerds), [github](http://github.com/nerdfiles))
2. brainix (brainix@gmail.com, [@brainix](http://twitter.com/brainix), [github](http://github.com/brainix))
3. gourneau (http://josh.gourneau.com/, [@gourneau](http://twitter.com/gourneau), [github](http://github.com/gourneau))

#REQS

1. [ccv](http://libccv.org/post/introducing-ccv-milestone/) (for FacePi)
2. [pareidoloop](http://iobound.com/pareidoloop/) (for FacePi)
3. D&D Profile -> Twitter Web Presence/Identity 

#NOTES

1. Twitter BG: http://t.wallpaperweb.org/wallpaper/nature/1600x1200/Deer_Cave_Mulu_National_Park_Borneo_Malaysia.jpg from http://community.allhiphop.com/discussion/comment/4251952/#Comment_4251952

#IDEAS

	* GesturePi (ascii-image-tile gesture-invoked snapshots from USB camera input as target for hopfield system that quickly learns to isolate arbitary entites from focal point average-frames within bounds determined by concentric circles, functioning as a finite-Cartesian ergonomic UI; essentially, pointing invokes or triggers the bounded-matrix as gestures play on canonical images developed from ascii-tiles; it's simple tile printing as a memory structure for hopfield networks; but gesture differentiation from images is important; a USB camera could start video from base pointing-gesture, then wait until gestures to interpret canonical geometric form contrasts derived from ascii-tile variations -- if a dense form is recorded by the USB camera, this outlines an initial snapshot-frame, where the density travels implies an geometric norm-pattern that serves as training data to gesture UI): For issuing commands.

			* |	-----G<---------------------- |
			* |	    / 	\					  |
			* |	   / 	 \  [O]				  |
			* |--/(G)-------G^-\------^(O)----|
			* |			     |/	\      /     \|
			* |              |\	 \----O>     /|
			* |	----------------------------- |

	* CLI for GesturePi (for quickly and in automated fashion A/B testing the UI; gestures/commands should tell us something about positive results in manipulating image-tiles)
		* #notes For A/B testing reality-feedback system
	* FacePi (evolutionary_face_fitness_generator :: hopfield_recurrent_ccv_trainer; ascii face-maps written in coffeejson): For a dragon that can love /you/ back; 
	* FlyPi ([pi-motor](https://github.com/rakeshpai/pi-motor); #see AR Drone 2.0 since it gets "miraculous" testimonials) : For fine-flight movement (two motors). Consider ``cputhrottle`` to choke the Pi into subtlty. #idea Raj has suggested a gyroscope. #consider [MPU-6050 6DOF](http://www.ebay.com/itm/MPU-6050-6DOF-3-Axis-Gyroscope-Accelerometer-Module-for-Arduino-DIY-/280952652299)
	* Pyrrative (Sui generis species generation from narrative models; TBD): For the character-trait edge in evolutionary scenarios with environment activity strictures over agent-object dynamics.
		* Web scraping (http://www.thefullwiki.org/Dragon_(Dungeons_%26_Dragons)#Rattelyr_dragon, http://quiz.thefullwiki.org/Dragon_(Dungeons_&_Dragons)?print=1) with #pandoc; e.g. $ pandoc -f html -t json ${url} #with some grep)
	* Epigenetic Constraints (@see [1](http://www.nature.com/nbt/journal/v30/n8/full/nbt.2269.html, http://www.nature.com/news/artificial-jellyfish-built-from-rat-cells-1.11046)): For discussion of lowest cost materials for a biosynthetic shell/husk.
	* Species descriptive topolgy system based on ┌ through ╋  at [copypastecharacter.com](http://copypastecharacter.com/all-characters)
	* DNS Ideas: ``http://drag.one/``, ``http://humano.ide/``, ``http://en.te/, http://mindflaye.re/`` (the "e" indicates W3C PROV "Entity" status of ontology)
	* Hardwar: Dual Altoids Tin+Cedar Wood Exoskelaton Chassis mounting polymer solar cell (PSC)/graphene wing-span redundant nanopower grid system and synchronized visuodata input camera systems [2](http://physicsworld.com/cws/article/news/2012/jan/26/graphene-could-be-a-perfect-absorber-of-light)
	* Emotion Trending System based on Descriptive Markup Analysis [3](http://www.w3.org/TR/emotionml/) on GPS Tracking of localized Twitter/Foursquare Profiles
	* Consider changing project name to "django_dragon"
	* Need pseudoendocrine system layout #hardwar
	* Need audition system

#LEFTOVERS

1. pandoc -f html -t json "http://www.thefullwiki.org/Dragon_(Dungeons_%26_Dragons)#wikipedia_Pyroclastic_dragon
2. py -c "from bs4 import BeautifulSoup;" #get #id'd content from pandoc
3. ...

#LICENSE

See [LICENSE](LICENSE).

